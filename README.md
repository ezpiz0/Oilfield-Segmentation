# Решение хакатона Роснефти - Семантическая сегментация месторождений

## Описание проекта

Решение задачи семантической сегментации карт месторождений с использованием глубокого обучения на основе архитектуры SegFormer (MIT-B5). Проект разработан для хакатона Роснефти 2025 и позволяет автоматически сегментировать изображения месторождений на 40 различных классов с высокой точностью.

## Оглавление

- [Архитектура решения](#архитектура-решения)
- [Системные требования](#системные-требования)
- [Установка](#установка)
- [Структура проекта](#структура-проекта)
- [Быстрый запуск](#быстрый-запуск)
- [Описание решения](#описание-решения)
- [Метрики качества](#метрики-качества)
- [Возможные проблемы](#возможные-проблемы)

---

## Архитектура решения

### SegFormer (MIT-B5)

Выбранная архитектура оптимальна для задачи сегментации карт месторождений благодаря следующим преимуществам:

**Ключевые особенности:**
- Self-attention механизм для понимания глобального контекста изображения
- Иерархическая структура MIT-B5 с 84 миллионами параметров
- Многомасштабное извлечение признаков
- Высокая точность сегментации (Validation Dice: 0.9949)

```
Вход (640x640 или 3000x3000)
    ↓
SegFormer Encoder (MIT-B5)
    ↓ Self-Attention для глобального контекста
Hierarchical Feature Extraction
    ↓ Многомасштабные признаки
SegFormer Decoder
    ↓
Выход: 40 классов (0-39)
```

### Технический стек

- **Модель:** SegFormer с MIT-B5 backbone
- **Фреймворк:** PyTorch 2.7.0
- **Параметры модели:** 84,624,104 (~84M)
- **Классы:** 40 (значения 0-215, маппинг в 0-39)
- **GPU:** Протестировано на NVIDIA GeForce RTX 3090 Ti (24 GB)

---

## Системные требования

### Минимальные требования

- **ОС:** Windows 10/11, Linux (Ubuntu 20.04+), macOS
- **Python:** 3.10 или выше (тестировалось на Python 3.12.9)
- **CUDA:** 11.8 или выше (для GPU)
- **GPU:** NVIDIA с минимум 12 GB VRAM
  - Рекомендуется: RTX 3090/4090, A100, V100
  - Тестировалось на: NVIDIA GeForce RTX 3090 Ti (24 GB)
- **RAM:** Минимум 32 GB
- **Свободное место на диске:** ~15 GB
  - Модель: ~1 GB
  - Данные: ~10 GB
  - Временные файлы: ~5 GB

### Версии драйверов

- **NVIDIA Driver:** 522.06 или выше (тестировалось на 572.83)
- **CUDA Toolkit:** 11.8 или 12.x
- **cuDNN:** 8.9.0 или выше

---

## Установка

### Шаг 1: Создание виртуального окружения

Рекомендуется использовать виртуальное окружение для изоляции зависимостей:

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/macOS:**
```bash
python -m venv venv
source venv/bin/activate
```

### Шаг 2: Установка PyTorch с CUDA

Выберите версию в зависимости от вашей версии CUDA:

**Для CUDA 12.8 (рекомендуется):**
```bash
pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu128
```

**Для CUDA 11.8:**
```bash
pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu118
```

**Для CPU (не рекомендуется, очень медленно):**
```bash
pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0
```

### Шаг 3: Установка остальных зависимостей

```bash
pip install -r requirements.txt
```

### Шаг 4: Проверка установки

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
```

**Ожидаемый вывод:**
```
PyTorch: 2.7.0+cu118
CUDA: True
GPU: NVIDIA GeForce RTX 3090 Ti
```

---

## Структура проекта

```
rosneft-segmentation/
├── pipeline.ipynb              # Полное обучение модели
├── inference.ipynb             # Быстрая генерация предсказаний
├── requirements.txt            # Зависимости проекта
├── README.md                   # Документация
│
├── data_mkGYPLg/              # Тренировочные данные (не в репозитории)
│   ├── input/                 # 10,000 изображений (640x640 RGB)
│   └── target/                # 10,000 масок сегментации
│
├── predict_input/              # Тестовые изображения (не в репозитории)
│                               # 100 изображений (3000x3000)
│
└── output/                     # Результаты (создаётся автоматически)
    ├── models/
    │   ├── best.pth           # Лучшая модель по метрике Dice
    │   └── last.pth           # Последний чекпоинт
    ├── predictions/
    │   └── predict_target/    # 100 предсказанных масок
    ├── predict_target.zip     # Файл для отправки
    └── training_history.png   # График метрик обучения
```

---

## Быстрый запуск

### Вариант 1: Генерация предсказаний (модель уже обучена)

Используйте `inference.ipynb`, если у вас уже есть обученная модель.

**Условия:**
- Модель обучена (есть файл `output/models/best.pth` или `last.pth`)
- Нужно только сгенерировать `predict_target.zip`

**Шаги:**
1. Откройте `inference.ipynb` в Jupyter Notebook/Lab или VS Code
2. Проверьте путь к данным (по умолчанию: `D:\Downloads\Hach_rosn`)
3. Запустите: **Kernel → Restart & Run All**
4. Дождитесь завершения (~5-10 минут на RTX 3090 Ti)
5. Результат: `output/predict_target.zip` готов к отправке

**Ожидаемый результат:**
```
Размер архива: ~5.3 MB (< 6 MB)
Файлов в архиве: 100
Формат: grayscale PNG (uint8)
Размер масок: 3000x3000
```

### Вариант 2: Полное обучение с нуля

Используйте `pipeline.ipynb` для полного цикла обучения.

**Возможности:**
- Обучение модели с нуля
- Получение метрик и графиков
- Автоматическая генерация submission файла

**Шаги:**
1. Откройте `pipeline.ipynb`
2. Проверьте путь к данным в ячейке 4:
   ```python
   BASE_DIR = Path(r'D:\Downloads\Hach_rosn')  # Измените на ваш путь
   ```
3. Запустите: **Kernel → Restart & Run All**
4. Обучение займет ~4-6 часов (30 эпох с Early Stopping)
5. После обучения автоматически создастся `output/predict_target.zip`

**Временные затраты:**
- Установка зависимостей: ~2 минуты
- Анализ и подготовка данных: ~5 минут
- Обучение: ~4-6 часов (с Early Stopping)
- Генерация предсказаний: ~10-15 минут
- Сохранение результатов: ~1 минута

---

## Описание решения

### Параметры обучения

```python
# Конфигурация модели
MODEL_NAME = 'nvidia/mit-b5'         # SegFormer-B5 (84M параметров)
NUM_CLASSES = 40                     # 40 уникальных классов (0-39)
BATCH_SIZE = 4                       # Оптимально для 24GB VRAM
NUM_EPOCHS = 30                      # С Early Stopping (patience=10)
LEARNING_RATE = 6e-5                 # Fine-tuning learning rate
WEIGHT_DECAY = 0.01                  # L2 регуляризация
RANDOM_STATE = 42                    # Воспроизводимость

# Sliding Window для инференса
TILE_SIZE = 640                      # Размер тайла
TILE_OVERLAP = 192                   # Перекрытие (30%)

# Разделение данных
TRAIN_SIZE = 9700                    # 97% для обучения
VAL_SIZE = 300                       # 3% для валидации
```

### Функции потерь

Комбинированная функция потерь для оптимального баланса:

- **Focal Loss (50%)** - борьба с дисбалансом классов
- **Dice Loss (50%)** - максимизация overlap между предсказанием и ground truth

### Оптимизация

- **AdamW optimizer** (lr=6e-5, weight_decay=0.01)
- **Cosine Annealing scheduler** (T_max=30, eta_min=1e-6)
- **Mixed Precision Training (AMP)** для ускорения обучения
- **Early Stopping** (patience=10) для предотвращения переобучения

### Аугментации данных

Только для тренировочного датасета:

- Horizontal flip (p=0.5)
- Vertical flip (p=0.5)
- Rotation: 0°, 90°, 180°, 270° (p=0.5)
- Brightness adjust (0.8-1.2, p=0.5)
- Contrast adjust (0.8-1.2, p=0.5)

### Инференс (Sliding Window + Gaussian Weighting)

- **Tile size:** 640x640
- **Overlap:** 192 пикселей (30%)
- **Gaussian Weighting** (σ = tile_size/4) для плавного смешивания краев тайлов
- **Усреднение вероятностей** (не классов) перед argmax
- Поддержка обработки больших изображений 3000x3000

### Preprocessing

1. **Маппинг значений:**
   - Оригинальные значения масок: 0, 25, 30, ..., 215 (40 уникальных)
   - Маппинг в классы: 0-39 для обучения
   - Обратный маппинг при генерации submission

2. **Нормализация:** ImageNet mean/std

3. **Аугментации:** только для train датасета

---

## Метрики качества

### Ожидаемые результаты

- **Validation Dice:** 0.9949 (99.49%)
- **Validation IoU:** 0.99+
- **Submission размер:** ~5.3 MB (< 6 MB limit)

### Описание метрик

**1. Dice Score (основная метрика)**
- Формула: `2 * |X ∩ Y| / (|X| + |Y|)`
- Диапазон: 0-1 (выше = лучше)
- Измеряет overlap между предсказанием и ground truth

**2. IoU (Intersection over Union)**
- Формула: `|X ∩ Y| / |X ∪ Y|`
- Диапазон: 0-1 (выше = лучше)
- Альтернативная метрика overlap

**3. Combined Loss**
- 50% Focal Loss (борьба с дисбалансом классов)
- 50% Dice Loss (максимизация overlap)

### Оценка времени выполнения

**С GPU (RTX 3090 Ti - 24 GB):**

| Этап | Время |
|------|-------|
| Подготовка данных | ~5 минут |
| Одна эпоха обучения | ~8-10 минут |
| Полное обучение | ~6-8 часов |
| Инференс (100 изображений) | ~10-15 минут |
| **ИТОГО** | **~6.5-8.5 часов** |

**С GPU (RTX 3060/3070 - 8-12 GB):**
- Потребуется уменьшить `BATCH_SIZE = 2`
- Обучение займет ~6-8 часов

**Без GPU (CPU):**
- Не рекомендуется
- Обучение займет 30+ часов
- Инференс: 1-2 часа

---

## Формат выходных данных

### Архив `predict_target.zip`

- **Файлов:** 100 (0.png - 99.png)
- **Размер каждого:** 3000x3000 пикселей
- **Формат:** grayscale PNG, uint8
- **Значения пикселей:** 0-215 (оригинальные значения классов)
- **Общий размер:** ~5.3 MB (< 6 MB лимит)

---

## Возможные проблемы

### 1. CUDA Out of Memory

**Решение:** Уменьшите batch size в конфигурации
```python
# В ячейке 4 измените:
BATCH_SIZE = 2  # вместо 4
```

### 2. Модуль не найден

**Решение:** Установите зависимости вручную
```bash
pip install torch==2.7.0 torchvision==0.22.0 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

### 3. Неправильные пути к данным

**Решение:** Измените пути в конфигурации
```python
# В ячейке 4 (Config) измените:
BASE_DIR = Path(r'C:\ваш\путь\к\Hach_rosn')  # Ваш путь
```

### 4. Медленное обучение на CPU

**Решение:** Используйте GPU. На CPU обучение займет 30+ часов.

### 5. Проблемы с DataLoader на Windows

**Решение:** Уже исправлено в коде
```python
NUM_WORKERS = 0  # Обязательно для Windows
```

### 6. Ошибка при загрузке модели SegFormer

**Решение:** Убедитесь в наличии интернет-соединения (модель скачивается с HuggingFace)

---

## Техническая поддержка

### Проверка установки

```bash
# Проверка PyTorch и CUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"

# Проверка GPU
python -c "import torch; print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU')"
```

### Логи обучения

- Все метрики выводятся в реальном времени
- Прогресс-бары для каждой эпохи
- Автоматическое сохранение лучшей модели

---

## Итоги

Решение оптимизировано для:

- **Эффективности** - 5-8 часов полного обучения
- **Точности** - Validation Dice: 0.9949
- **Простоты запуска** - один клик в Jupyter
- **Совместимости** - Windows/Linux/macOS
- **Автоматизации** - автоматическая генерация submission файла

---

## Информация о проекте

**Хакатон:** Роснефть 2025  
**Дата:** 2025-11-16  
**Модель:** SegFormer (nvidia/mit-b5)  
**Фреймворк:** PyTorch 2.7.0  
**Тестовая конфигурация:** NVIDIA RTX 3090 Ti (24GB)

---

## Лицензия

Этот проект был разработан для участия в хакатоне Роснефти.
