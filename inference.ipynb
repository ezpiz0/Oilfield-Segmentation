{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, zipfile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Seed для воспроизводимости\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"Seed: 42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Classes: 40\n",
      "Predict input: D:\\Downloads\\Hach_rosn\\predict_input\n",
      "Model path: D:\\Downloads\\Hach_rosn\\output\\models\\best.pth\n"
     ]
    }
   ],
   "source": [
    "# Конфигурация\n",
    "class Config:\n",
    "    BASE_DIR = Path(r'D:\\Downloads\\Hach_rosn')\n",
    "    TRAIN_TARGET_DIR = BASE_DIR / 'data_mkGYPLg' / 'target'\n",
    "    PREDICT_INPUT_DIR = BASE_DIR / 'predict_input'\n",
    "    OUTPUT_DIR = BASE_DIR / 'output'\n",
    "    MODELS_DIR = OUTPUT_DIR / 'models'\n",
    "    PREDICTIONS_DIR = OUTPUT_DIR / 'predictions'\n",
    "    \n",
    "    MODEL_NAME = 'nvidia/mit-b5'\n",
    "    NUM_CLASSES = 40\n",
    "    TILE_SIZE = 640\n",
    "    TILE_OVERLAP = 256\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = Config()\n",
    "config.PREDICTIONS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Classes: {config.NUM_CLASSES}\")\n",
    "print(f\"Predict input: {config.PREDICT_INPUT_DIR}\")\n",
    "print(f\"Model path: {config.MODELS_DIR / 'best.pth'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7db088e66614d50a539e302b517cd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Уникальные значения: [0, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215]\n",
      "Количество классов: 40\n",
      "\n",
      "Маппинг создан: 40 значений → 40 классов\n",
      "Примеры: {0: 0, 25: 1, 30: 2, 35: 3, 40: 4}\n"
     ]
    }
   ],
   "source": [
    "# Создание маппинга значений\n",
    "mask_files = list(config.TRAIN_TARGET_DIR.glob('*.png'))[:500]\n",
    "unique_vals = set()\n",
    "\n",
    "for mf in tqdm(mask_files, desc='Scanning'):\n",
    "    mask = np.array(Image.open(mf))\n",
    "    unique_vals.update(np.unique(mask).tolist())\n",
    "\n",
    "unique_vals = sorted(unique_vals)\n",
    "print(f\"\\nУникальные значения: {unique_vals}\")\n",
    "print(f\"Количество классов: {len(unique_vals)}\")\n",
    "\n",
    "# Маппинг: значение → класс\n",
    "value_to_class = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "class_to_value = {idx: val for val, idx in value_to_class.items()}\n",
    "\n",
    "print(f\"\\nМаппинг создан: {len(value_to_class)} значений → {len(unique_vals)} классов\")\n",
    "print(f\"Примеры: {dict(list(value_to_class.items())[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка SegFormer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b5 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Модель загружена: 84,624,104 параметров\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "print(\"Загрузка SegFormer\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    config.MODEL_NAME, \n",
    "    num_labels=config.NUM_CLASSES, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model = model.to(config.DEVICE)\n",
    "print(f\"✓ Модель загружена: {sum(p.numel() for p in model.parameters()):,} параметров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка весов из D:\\Downloads\\Hach_rosn\\output\\models\\last.pth...\n",
      "\n",
      "Модель загружена:\n",
      "Epoch: 30\n",
      "Val Dice: 0.9948\n",
      "Best Dice: 0.9949\n"
     ]
    }
   ],
   "source": [
    "# Загрузка весов лучшей модели\n",
    "best_model_path = config.MODELS_DIR / 'last.pth'\n",
    "\n",
    "if not best_model_path.exists():\n",
    "    raise FileNotFoundError(f\"Файл модели не найден: {best_model_path}\")\n",
    "\n",
    "print(f\"Загрузка весов из {best_model_path}...\")\n",
    "ckpt = torch.load(best_model_path, map_location=config.DEVICE, weights_only=False)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nМодель загружена:\")\n",
    "print(f\"Epoch: {ckpt['epoch']+1}\")\n",
    "print(f\"Val Dice: {ckpt['dice']:.4f}\")\n",
    "print(f\"Best Dice: {ckpt.get('best_dice', ckpt['dice']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor готов (с правильным Gaussian Weighting на вероятностях!)\n"
     ]
    }
   ],
   "source": [
    "# Predictor с ПРАВИЛЬНЫМ Gaussian Weighting (усреднение логитов, не классов!)\n",
    "class Predictor:\n",
    "    def __init__(self, model, device, class_to_value, tile_size=640, overlap=256):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.class_to_value = class_to_value\n",
    "        self.num_classes = len(class_to_value)\n",
    "        self.tile_size = tile_size\n",
    "        self.overlap = overlap\n",
    "        self.stride = tile_size - overlap\n",
    "        self.norm = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    def predict_tile(self, tile_pil):\n",
    "        \"\"\"Возвращает ВЕРОЯТНОСТИ (softmax)\"\"\"\n",
    "        tile = TF.to_tensor(tile_pil).unsqueeze(0).to(self.device)\n",
    "        tile = self.norm(tile)\n",
    "        with torch.no_grad(), autocast():\n",
    "            logits = self.model(pixel_values=tile).logits\n",
    "            logits = F.interpolate(logits, size=(self.tile_size, self.tile_size), \n",
    "                                   mode='bilinear', align_corners=False)\n",
    "            # ВАЖНО: возвращаем вероятности, не классы!\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "        return probs.cpu().numpy()[0]  # shape: (num_classes, H, W)\n",
    "    \n",
    "    def predict_large(self, img_pil):\n",
    "        w, h = img_pil.size\n",
    "        \n",
    "        # Накопление вероятностей для каждого класса\n",
    "        prob_sum = np.zeros((self.num_classes, h, w), dtype=np.float32)\n",
    "        weight_sum = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        # Создание Gaussian weight (плавное взвешивание)\n",
    "        c = self.tile_size // 2\n",
    "        y, x = np.ogrid[:self.tile_size, :self.tile_size]\n",
    "        dist = np.sqrt((x-c)**2 + (y-c)**2)\n",
    "        # Более плавное гауссовское ядро для лучшего смешивания\n",
    "        sigma = self.tile_size / 4  # Можно настроить (2, 3, 4, 5)\n",
    "        weight = np.exp(-dist**2 / (2*sigma**2))\n",
    "        weight = weight / weight.max()\n",
    "        \n",
    "        # Sliding window\n",
    "        n_h = (h - self.tile_size) // self.stride + 1\n",
    "        n_w = (w - self.tile_size) // self.stride + 1\n",
    "        \n",
    "        for i in range(n_h):\n",
    "            for j in range(n_w):\n",
    "                y1, x1 = i*self.stride, j*self.stride\n",
    "                y2, x2 = min(y1+self.tile_size, h), min(x1+self.tile_size, w)\n",
    "                \n",
    "                tile = img_pil.crop((x1, y1, x2, y2))\n",
    "                if tile.size != (self.tile_size, self.tile_size):\n",
    "                    padded = Image.new('RGB', (self.tile_size, self.tile_size))\n",
    "                    padded.paste(tile, (0, 0))\n",
    "                    tile = padded\n",
    "                \n",
    "                # Получаем вероятности (num_classes, tile_size, tile_size)\n",
    "                tile_probs = self.predict_tile(tile)\n",
    "                tile_probs = tile_probs[:, :y2-y1, :x2-x1]\n",
    "                tile_w = weight[:y2-y1, :x2-x1]\n",
    "                \n",
    "                # Взвешенное накопление вероятностей\n",
    "                prob_sum[:, y1:y2, x1:x2] += tile_probs * tile_w[np.newaxis, :, :]\n",
    "                weight_sum[y1:y2, x1:x2] += tile_w\n",
    "        \n",
    "        # Усреднение вероятностей\n",
    "        prob_avg = prob_sum / np.maximum(weight_sum[np.newaxis, :, :], 1e-6)\n",
    "        \n",
    "        # ТОЛЬКО ТЕПЕРЬ делаем argmax (на усредненных вероятностях!)\n",
    "        pred_classes = prob_avg.argmax(axis=0).astype(np.uint8)\n",
    "        \n",
    "        # Обратный маппинг: класс → оригинальное значение\n",
    "        pred_values = np.zeros_like(pred_classes)\n",
    "        for cls, val in self.class_to_value.items():\n",
    "            pred_values[pred_classes == cls] = val\n",
    "        \n",
    "        return pred_values\n",
    "\n",
    "predictor = Predictor(model, config.DEVICE, class_to_value, config.TILE_SIZE, config.TILE_OVERLAP)\n",
    "print(\"Predictor готов (с Gaussian Weighting на вероятностях)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Найдено изображений: 100\n",
      "Путь: D:\\Downloads\\Hach_rosn\\predict_input\n",
      "Sliding Window: 640x640, overlap=256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17624a99a3d7415e9fb15a1c2f8eb95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predictions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Маски сохранены: D:\\Downloads\\Hach_rosn\\output\\predictions\\predict_target\n",
      "\n",
      "Создание архива...\n",
      "Архив: D:\\Downloads\\Hach_rosn\\output\\predict_target.zip\n",
      "Размер: 5.28 MB\n",
      "Файлов: 100\n",
      "Размер в пределах нормы (<6 MB)\n",
      "\n",
      "Проверка архива:\n",
      "   Файлов: 100\n",
      "   Первые 3: ['0.png', '1.png', '10.png']\n",
      "   Последние 3: ['97.png', '98.png', '99.png']\n",
      "\n",
      "Проверка формата (0.png):\n",
      "   Размер: (3000, 3000)\n",
      "   Режим: L\n",
      "   Dtype: uint8\n",
      "   Значения: 0 - 210\n",
      "   Уникальных: 20\n"
     ]
    }
   ],
   "source": [
    "# Поиск изображений\n",
    "sub_imgs = sorted(list(config.PREDICT_INPUT_DIR.glob('*.png')))\n",
    "print(f\"\\nНайдено изображений: {len(sub_imgs)}\")\n",
    "print(f\"Путь: {config.PREDICT_INPUT_DIR}\")\n",
    "\n",
    "if len(sub_imgs) == 0:\n",
    "    raise FileNotFoundError(f\"Не найдены изображения в {config.PREDICT_INPUT_DIR}\")\n",
    "\n",
    "# Создать папку для масок\n",
    "pred_dir = config.PREDICTIONS_DIR / 'predict_target'\n",
    "if pred_dir.exists():\n",
    "    import shutil\n",
    "    shutil.rmtree(pred_dir)\n",
    "pred_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Sliding Window: {config.TILE_SIZE}x{config.TILE_SIZE}, overlap={config.TILE_OVERLAP}\")\n",
    "\n",
    "# Генерация масок\n",
    "for img_path in tqdm(sub_imgs, desc='Predictions'):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    pred_mask = predictor.predict_large(img)\n",
    "    \n",
    "    # Сохранить как grayscale uint8\n",
    "    pred_mask_uint8 = pred_mask.astype(np.uint8)\n",
    "    pred_image = Image.fromarray(pred_mask_uint8, mode='L')\n",
    "    pred_image.save(pred_dir / img_path.name)\n",
    "\n",
    "print(f\"\\nМаски сохранены: {pred_dir}\")\n",
    "\n",
    "# Создать архив\n",
    "zip_path = config.OUTPUT_DIR / 'predict_target.zip'\n",
    "if zip_path.exists():\n",
    "    zip_path.unlink()\n",
    "\n",
    "print(f\"\\nСоздание архива...\")\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for mask_file in sorted(pred_dir.glob('*.png')):\n",
    "        zipf.write(mask_file, arcname=mask_file.name)\n",
    "\n",
    "size_mb = zip_path.stat().st_size / (1024*1024)\n",
    "\n",
    "print(f\"Архив: {zip_path}\")\n",
    "print(f\"Размер: {size_mb:.2f} MB\")\n",
    "print(f\"Файлов: {len(list(pred_dir.glob('*.png')))}\")\n",
    "\n",
    "if size_mb > 6:\n",
    "    print(f\"ВНИМАНИЕ: Размер превышает 6 MB!\")\n",
    "else:\n",
    "    print(f\"Размер в пределах нормы (<6 MB)\")\n",
    "\n",
    "# Проверка архива\n",
    "with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "    files_in_zip = zipf.namelist()\n",
    "    print(f\"\\nПроверка архива:\")\n",
    "    print(f\"   Файлов: {len(files_in_zip)}\")\n",
    "    print(f\"   Первые 3: {files_in_zip[:3]}\")\n",
    "    print(f\"   Последние 3: {files_in_zip[-3:]}\")\n",
    "    \n",
    "    # Проверка формата\n",
    "    if len(files_in_zip) > 0:\n",
    "        with zipf.open(files_in_zip[0]) as f:\n",
    "            test_img = Image.open(f)\n",
    "            test_arr = np.array(test_img)\n",
    "            print(f\"\\nПроверка формата ({files_in_zip[0]}):\")\n",
    "            print(f\"   Размер: {test_img.size}\")\n",
    "            print(f\"   Режим: {test_img.mode}\")\n",
    "            print(f\"   Dtype: {test_arr.dtype}\")\n",
    "            print(f\"   Значения: {test_arr.min()} - {test_arr.max()}\")\n",
    "            print(f\"   Уникальных: {len(np.unique(test_arr))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rosneft_hack)",
   "language": "python",
   "name": "rosneft_hack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
